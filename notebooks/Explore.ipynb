{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import feedparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick get feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir ../data/feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python ../package/src/get_rss_feeds.py \\\n",
    "        --rss-url \"http://feeds.bbci.co.uk/news/politics/rss.xml\" \\\n",
    "        --json ../data/feeds/bbc3.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python ../package/src/get_rss_feeds.py \\\n",
    "        --rss-url \"http://feeds2.feedburner.com/ft/westminster\" \\\n",
    "        --json ../data/feeds/ft3.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python ../package/src/get_rss_feeds.py \\\n",
    "        --rss-url \"https://www.theguardian.com/politics/rss\" \\\n",
    "        --json ../data/feeds/guardian3.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bbc_url = \"http://feeds.bbci.co.uk/news/politics/rss.xml\"\n",
    "ft_url = \"http://feeds2.feedburner.com/ft/westminster\"\n",
    "gaurdian_url = \"https://www.theguardian.com/politics/rss\"\n",
    "\n",
    "data_sources = [bbc_url, ft_url, gaurdian_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for source in data_sources:\n",
    "    \n",
    "    # Find latest feeds\n",
    "    feed = fetch_latest_feed(source)\n",
    "    \n",
    "    save_feed_metadata(feed, db)\n",
    "    \n",
    "    fetch_articles\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> from tinydb import TinyDB, Query\n",
    ">>> db = TinyDB('path/to/db.json')\n",
    ">>> User = Query()\n",
    ">>> db.insert({'name': 'John', 'age': 22})\n",
    ">>> db.search(User.name == 'John')\n",
    "[{'name': 'John', 'age': 22}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Script to fetch news articles from RSS feeds and store text and meta data as a JSON file.\n",
    "@author: Chris Musselle\n",
    "\"\"\"\n",
    "# Standard libs\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# 3rd Party libs\n",
    "import requests\n",
    "import bs4\n",
    "import feedparser\n",
    "\n",
    "\n",
    "def get_articles(feed_url, json_filename='articles.json'):\n",
    "    \"\"\" Update a JSON file to hold article links, published data and text data \"\"\"\n",
    "\n",
    "    feed = feedparser.parse(feed_url)\n",
    "\n",
    "    # Read in articles already downloaded if they exist\n",
    "    if os.path.exists(json_filename):\n",
    "        JSON_articles = json.load(open(json_filename, 'r'))\n",
    "    else:\n",
    "        JSON_articles = {}\n",
    "\n",
    "    article_counter = 0\n",
    "\n",
    "    for item in feed['items']:\n",
    "\n",
    "        # Use title of the article as an id\n",
    "        title = item['title']\n",
    "\n",
    "        # Only process article if we have not done so already\n",
    "        if title not in JSON_articles:\n",
    "\n",
    "            # Store basic info from feed\n",
    "            article_url = item['link']\n",
    "            article_published_date = item['published']\n",
    "            JSON_articles[title] = {'url': article_url,\n",
    "                                    'published_date': article_published_date}\n",
    "\n",
    "            # Get full web content for link\n",
    "            r = requests.get(article_url)\n",
    "\n",
    "            # Parse HTML using BeautifulSoup\n",
    "            soup = bs4.BeautifulSoup(r.content, 'lxml')\n",
    "\n",
    "            # Find all the p tags\n",
    "            p_tags = soup.find_all(name='p')\n",
    "\n",
    "            # Extract just the text from the p tags\n",
    "            p_tags_text = [p.text for p in p_tags]\n",
    "\n",
    "            # Join all p tag strings by a newline\n",
    "            all_text = '\\n'.join(p_tags_text)\n",
    "\n",
    "            # Store and increment counter\n",
    "            JSON_articles[title]['text'] = all_text\n",
    "            article_counter += 1\n",
    "\n",
    "    # Write updated file.\n",
    "    with open(json_filename, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(JSON_articles, json_file, indent=4)\n",
    "\n",
    "    print('Added {} new articles'.format(article_counter))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Pass Arguments\n",
    "    args = sys.argv[1:]\n",
    "    feed_url = args[0]\n",
    "    filepath = args[1]\n",
    "\n",
    "    # Create the directory if it does not already exist\n",
    "    dirname = os.path.dirname(filepath)\n",
    "    if dirname:\n",
    "        if not os.path.exists(dirname):\n",
    "            os.makedirs(dirname)\n",
    "\n",
    "    # Get the latest articles and append to the JSON file given\n",
    "    print('Fetching articles for {}'.format(feed_url))\n",
    "    get_articles(feed_url, filepath)\n",
    "print('Saving to {}'.format(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bbc_feed = feedparser.parse(bbc_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ft_feed = feedparser.parse(ft_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaurdian_feed = feedparser.parse(gaurdian_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feed', 'entries', 'bozo', 'headers', 'href', 'status', 'encoding', 'version', 'namespaces'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_feed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feed', 'entries', 'bozo', 'headers', 'etag', 'updated', 'updated_parsed', 'href', 'status', 'encoding', 'version', 'namespaces'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_feed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feed', 'entries', 'bozo', 'headers', 'etag', 'href', 'status', 'encoding', 'version', 'namespaces'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaurdian_feed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 'http://www.w3.org/2005/Atom',\n",
       " 'content': 'http://purl.org/rss/1.0/modules/content/',\n",
       " 'dc': 'http://purl.org/dc/elements/1.1/',\n",
       " 'media': 'http://search.yahoo.com/mrss/'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_feed['namespaces']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 'http://www.w3.org/2005/Atom',\n",
       " 'content': 'http://purl.org/rss/1.0/modules/content/',\n",
       " 'dc': 'http://purl.org/dc/elements/1.1/',\n",
       " 'feedburner': 'http://rssnamespace.org/feedburner/ext/1.0',\n",
       " 'slash': 'http://purl.org/rss/1.0/modules/slash/',\n",
       " 'sy': 'http://purl.org/rss/1.0/modules/syndication/',\n",
       " 'wfw': 'http://wellformedweb.org/CommentAPI/'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_feed['namespaces']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feedburner_info': {'uri': 'ft/westminster'},\n",
       " 'language': 'en',\n",
       " 'link': 'http://blogs.ft.com/westminster',\n",
       " 'links': [{'href': 'http://blogs.ft.com/westminster',\n",
       "   'rel': 'alternate',\n",
       "   'type': 'text/html'},\n",
       "  {'href': 'http://feeds.feedburner.com/ft/westminster',\n",
       "   'rel': 'self',\n",
       "   'type': 'application/rss+xml'},\n",
       "  {'href': 'http://pubsubhubbub.appspot.com/',\n",
       "   'rel': 'hub',\n",
       "   'type': 'text/html'}],\n",
       " 'subtitle': 'Jim Pickard and Kiran Stacey share their views on the UK’s political scene for the Financial Times',\n",
       " 'subtitle_detail': {'base': 'http://feeds2.feedburner.com/ft/westminster',\n",
       "  'language': None,\n",
       "  'type': 'text/html',\n",
       "  'value': 'Jim Pickard and Kiran Stacey share their views on the UK’s political scene for the Financial Times'},\n",
       " 'sy_updatefrequency': '1',\n",
       " 'sy_updateperiod': 'hourly',\n",
       " 'title': 'Westminster blog',\n",
       " 'title_detail': {'base': 'http://feeds2.feedburner.com/ft/westminster',\n",
       "  'language': None,\n",
       "  'type': 'text/plain',\n",
       "  'value': 'Westminster blog'},\n",
       " 'updated': 'Wed, 19 Apr 2017 10:50:00 +0000',\n",
       " 'updated_parsed': time.struct_time(tm_year=2017, tm_mon=4, tm_mday=19, tm_hour=10, tm_min=50, tm_sec=0, tm_wday=2, tm_yday=109, tm_isdst=0)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_feed['feed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_updated_parsed = bbc_feed['feed']['updated_parsed']\n",
    "last_updated = bbc_feed['feed']['updated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status = bbc_feed['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_url = \"https://www.theguardian.com/politics/2017/may/06/andy-burnham-denies-jeremy-corbyn-snub-manchester-rally\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "\n",
    "content = requests.get(g_url)\n",
    "content.ok\n",
    "\n",
    "soup = BeautifulSoup(content.content, \"html5lib\")\n",
    "\n",
    "print(soup.get_text())\n",
    "\n",
    "x = soup.select('div.content__main')[0]\n",
    "x.find(name='h1')\n",
    "\n",
    "x.get_text()\n",
    "\n",
    "ps = x.find_all(name='p')\n",
    "\n",
    "len(ps)\n",
    "\n",
    "p = ps[0]\n",
    "\n",
    "paras = [p.get_text() for p in ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New mayor for Greater Manchester blames prior commitments for no-show at victory rally with party leader',\n",
       " '\\nChris Johnston',\n",
       " '\\n\\nSaturday 6 May 2017 15.39\\xa0BST\\n\\n\\nFirst published on Saturday 6 May 2017 14.44\\xa0BST\\n\\n',\n",
       " 'The new Labour mayor of Greater Manchester, Andy Burnham, has denied snubbing Jeremy Corbyn after failing to join his party leader at a rally in the city following his election victory.',\n",
       " 'Burnham said his absence from the event was “not in the slightest” intended as a snub, and that he had told Corbyn’s office earlier in the week that he had prior engagements.',\n",
       " 'Burnham told the BBC: “I had made it clear … that I wouldn’t be able to be at the rally at 7 o’clock, because I had a lot of commitments, including family commitments. Jeremy came, fair enough, because people wanted to enjoy the moment.”',\n",
       " 'Ian Lavery, Labour’s national campaigns coordinator, also dismissed speculation of a rift between Corbyn and Burnham.',\n",
       " 'Speaking in Leicester on Saturday, Corbyn described the former health secretary’s victory in Manchester as “brilliant”.',\n",
       " 'Meanwhile, Burnham said Britain was in “difficult, challenging times”.',\n",
       " '‘We are living through something of a crisis in politics right now, with Brexit and everything that involves,” he said.',\n",
       " 'Burnham denied Labour was split, insisting the party was “fighting as one” for victory in the 8 June general election. But he accepted that Thursday’s local elections, in which Labour lost more than 100 councillors, painted a “very mixed picture for the party”.',\n",
       " 'Corbyn said on Saturday that the results were disappointing and that Labour faced a “huge challenge” in the general election. However, he claimed that the gap with the Tories was “not as great as the pundits are saying”.',\n",
       " '“We know this is no small task – it is a challenge on a historic scale. But we, the whole Labour movement and the British people, can’t afford not to seize our moment,” he told supporters. ',\n",
       " '“We have five weeks to win the general election so we can fundamentally transform Britain for the many, not the few. I say to tax cheats, the rip-off bosses, the greedy bankers: enough is enough. The people of Britain are taking our money back.” ',\n",
       " 'Corbyn won cheers after repeating his call for the prime minister to face him in a televised debate.',\n",
       " '“I have a message for Theresa May: If you feel the need to go on about what a great leader you are, then show it by debating with me in this election campaign. We are for the many, you’re for the few.”',\n",
       " 'Burnham, who has twice stood for the Labour leadership, said it was “very humbling” to become Greater Manchester’s first mayor, having won 63% of the vote. ',\n",
       " 'Some commentators have argued that Burnham’s win was largely due to his personal popularity rather than that of the Labour party.',\n",
       " 'He has appointed the Manchester city council leader Sir Richard Leese as deputy mayor for business and the economy, and the former immigration minister Beverley Hughes as deputy mayor for policing. ']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New mayor for Greater Manchester blames prior commitments for no-show at victory rally with party leader',\n",
       " '\\nChris Johnston',\n",
       " '\\n\\nSaturday 6 May 2017 15.39\\xa0BST\\n\\n\\nFirst published on Saturday 6 May 2017 14.44\\xa0BST\\n\\n',\n",
       " 'The new Labour mayor of Greater Manchester, Andy Burnham, has denied snubbing Jeremy Corbyn after failing to join his party leader at a rally in the city following his election victory.',\n",
       " 'Burnham said his absence from the event was “not in the slightest” intended as a snub, and that he had told Corbyn’s office earlier in the week that he had prior engagements.',\n",
       " 'Burnham told the BBC: “I had made it clear … that I wouldn’t be able to be at the rally at 7 o’clock, because I had a lot of commitments, including family commitments. Jeremy came, fair enough, because people wanted to enjoy the moment.”',\n",
       " 'Ian Lavery, Labour’s national campaigns coordinator, also dismissed speculation of a rift between Corbyn and Burnham.',\n",
       " 'Speaking in Leicester on Saturday, Corbyn described the former health secretary’s victory in Manchester as “brilliant”.',\n",
       " 'Meanwhile, Burnham said Britain was in “difficult, challenging times”.',\n",
       " '‘We are living through something of a crisis in politics right now, with Brexit and everything that involves,” he said.',\n",
       " 'Burnham denied Labour was split, insisting the party was “fighting as one” for victory in the 8 June general election. But he accepted that Thursday’s local elections, in which Labour lost more than 100 councillors, painted a “very mixed picture for the party”.',\n",
       " 'Corbyn said on Saturday that the results were disappointing and that Labour faced a “huge challenge” in the general election. However, he claimed that the gap with the Tories was “not as great as the pundits are saying”.',\n",
       " '“We know this is no small task – it is a challenge on a historic scale. But we, the whole Labour movement and the British people, can’t afford not to seize our moment,” he told supporters. ',\n",
       " '“We have five weeks to win the general election so we can fundamentally transform Britain for the many, not the few. I say to tax cheats, the rip-off bosses, the greedy bankers: enough is enough. The people of Britain are taking our money back.” ',\n",
       " 'Corbyn won cheers after repeating his call for the prime minister to face him in a televised debate.',\n",
       " '“I have a message for Theresa May: If you feel the need to go on about what a great leader you are, then show it by debating with me in this election campaign. We are for the many, you’re for the few.”',\n",
       " 'Burnham, who has twice stood for the Labour leadership, said it was “very humbling” to become Greater Manchester’s first mayor, having won 63% of the vote. ',\n",
       " 'Some commentators have argued that Burnham’s win was largely due to his personal popularity rather than that of the Labour party.',\n",
       " 'He has appointed the Manchester city council leader Sir Richard Leese as deputy mayor for business and the economy, and the former immigration minister Beverley Hughes as deputy mayor for policing. ']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_sentences(text, pattern):\n",
    "    \n",
    "    parts = re.split(pattern=pattern, string=text)\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Burnham told the BBC: “I had made it clear … that I wouldn’t be able to be at the rally at 7 o’clock, because I had a lot of commitments, including family commitments. Jeremy came, fair enough, because people wanted to enjoy the moment.”'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Burnham told the BBC: “I had made it clear … that I wouldn’t be able to be at the rally at 7 o’clock, because I had a lot of commitments, including family commitmen',\n",
       " 'ts',\n",
       " 'Je',\n",
       " 'remy came, fair enough, because people wanted to enjoy the moment.”do',\n",
       " 'ne',\n",
       " 'An',\n",
       " 'd then ..']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'([a-z]{2})\\.  ?([A-Z][a-z ])', paras[5] + 'done.  And then ..', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource 'tokenizers/punkt/PY3/english.pickle' not found.\n  Please use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - '/Users/cmusselle/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-e97ba6891837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Good morning Dr. Adams. The patient is waiting for you in room number 3.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Good morning Dr. Adams.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'The patient is waiting for you in room number 3.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cmusselle/anaconda3/envs/rss-miner/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cmusselle/anaconda3/envs/rss-miner/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cmusselle/anaconda3/envs/rss-miner/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cmusselle/anaconda3/envs/rss-miner/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'tokenizers/punkt/PY3/english.pickle' not found.\n  Please use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - '/Users/cmusselle/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************"
     ]
    }
   ],
   "source": [
    ">>> from nltk import tokenize\n",
    ">>> p = \"Good morning Dr. Adams. The patient is waiting for you in room number 3.\"\n",
    ">>> tokenize.sent_tokenize(p)\n",
    "['Good morning Dr. Adams.', 'The patient is waiting for you in room number 3.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "doc = nlp(paras[5])\n",
    "\n",
    "doc\n",
    "\n",
    "list(doc.sents)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
